# PredicciÃ³n de Ganadores de Partidos de Tenis ğŸ†ğŸ¾  

## DescripciÃ³n ğŸ“–  
Este proyecto tiene como objetivo desarrollar y evaluar modelos de clasificaciÃ³n para predecir el ganador de partidos de tenis utilizando datos histÃ³ricos de partidos oficiales de la ATP. Se exploraron diferentes algoritmos de machine learning, se realizÃ³ un anÃ¡lisis exploratorio de datos (EDA) y se optimizaron los modelos para mejorar su rendimiento. AdemÃ¡s, el proyecto estÃ¡ estructurado utilizando Kedro, con el fin de conseguir un desarrollo reproducible y escalable de las pipelines en Data Processing y Data Science.

## Dataset ğŸ“Š  
El dataset utilizado contiene informaciÃ³n de partidos de tenis desde el aÃ±o 2000 hasta 2025. Algunas de las variables principales incluyen:  

- **Rank_1, Rank_2**: Ranking de los jugadores.  
- **Pts_1, Pts_2**: Puntos ATP de los jugadores.  
- **Odd_1, Odd_2**: Probabilidades de apuestas para cada jugador.  
- **Winner_binary**: Variable objetivo (1 si gana el jugador 1, 0 si gana el jugador 2).  
- **Gano_el_que_tenia_mas_puntos** y **Gano_el_que_tenia_menor_odd**: Variables derivadas a partir del dataset original.  

## Modelos Utilizados ğŸ¤–  
Se probaron dos algoritmos de clasificaciÃ³n:  

1. **SGDClassifier**
2. **KNeighborsClassifier**
3. **XGBoost**

## MetodologÃ­a ğŸ› ï¸  
- **AnÃ¡lisis exploratorio de datos (EDA)** con histogramas, grÃ¡ficos de correlaciÃ³n y visualizaciones.  
- **Preprocesamiento**: Escalado de variables con `StandardScaler` , Onehot encoding para tratar las variables categoricas y Feature Engineering para nuevas variables predictoras.  
- **Balanceo de clases**: Uso de **SMOTE** para mejorar el rendimiento en clases desbalanceadas.
- **Entrenamiento y evaluaciÃ³n de modelos**: Uso de confusion_matrix, classification_report y cross_val_score para evaluaciÃ³n  

## Resultados ğŸ“ˆ  
| Modelo               | Accuracy | PrecisiÃ³n | Recall | F1-Score |  
|----------------------|---------|-----------|--------|----------|  
| **SGDClassifier**    | 76%     | 0.81      | 0.76   | 0.75     |  
| **KNeighborsClassifier** | 98% | 0.98      | 0.98   | 0.98     |
| **XGBoost**          | 99%     | 0.99      | 0.99   | 0.99     |

ğŸ“Œ **Todos los modelos superaron el baseline de predicciÃ³n unicamente tomando en cuenta si el ganador tenia el mejor ranking (65% de accuracy).**  

## Conclusiones ğŸ   
âœ”ï¸ **KNeighborsClassifier** junto con **XGBoost** tuvieron un rendimiento alto.  

âœ”ï¸ Las variables derivadas (feature engineering) ayudaron a mejorar la precisiÃ³n del modelo.

âœ”ï¸ KNN mejorÃ³ mediante Cross Validation llegando a 99% de accuracy.

âœ”ï¸ Kedro permitiÃ³ una estructura clara, modular y reproducible del proyecto
