# PredicciÃ³n de Ganadores de Partidos de Tenis ğŸ†ğŸ¾  

## DescripciÃ³n ğŸ“–  
Este proyecto tiene como objetivo desarrollar y evaluar modelos de clasificaciÃ³n para predecir el ganador de partidos de tenis utilizando datos histÃ³ricos de partidos oficiales. Se exploraron diferentes algoritmos de machine learning, se realizÃ³ un anÃ¡lisis exploratorio de datos (EDA) y se optimizaron los modelos para mejorar su rendimiento.  

## Dataset ğŸ“Š  
El dataset utilizado contiene informaciÃ³n de partidos de tenis desde el aÃ±o 2000 hasta 2025. Algunas de las variables principales incluyen:  

- **Rank_1, Rank_2**: Ranking de los jugadores.  
- **Pts_1, Pts_2**: Puntos ATP de los jugadores.  
- **Odd_1, Odd_2**: Probabilidades de apuestas para cada jugador.  
- **Winner_binary**: Variable objetivo (1 si gana el jugador 1, 0 si gana el jugador 2).  
- **Gano_el_que_tenia_mas_puntos** y **Gano_el_que_tenia_menor_odd**: Variables derivadas a partir del dataset original.  

## Modelos Utilizados ğŸ¤–  
Se probaron dos algoritmos de clasificaciÃ³n:  

1. **SGDClassifier** (Stochastic Gradient Descent): Modelo lineal basado en descenso de gradiente estocÃ¡stico.  
2. **KNeighborsClassifier** (K-NN): Modelo basado en vecinos mÃ¡s cercanos.  

## MetodologÃ­a ğŸ› ï¸  
- **AnÃ¡lisis exploratorio de datos (EDA)** con histogramas, grÃ¡ficos de correlaciÃ³n y boxplots.  
- **Preprocesamiento**: Escalado de variables con `StandardScaler` , Onehot encoding para tratar las variables categoricas y Feature Engineering para nuevas variables predictoras.  
- **Balanceo de clases**: Uso de **SMOTE** para mejorar el rendimiento en clases desbalanceadas.  
- **OptimizaciÃ³n**: Se aplicÃ³ **Grid Search** para ajustar los hiperparÃ¡metros de los modelos.  

## Resultados ğŸ“ˆ  
| Modelo               | Accuracy | PrecisiÃ³n | Recall | F1-Score |  
|----------------------|---------|-----------|--------|----------|  
| **SGDClassifier**    | 73%     | 0.72      | 0.73   | 0.72     |  
| **KNeighborsClassifier** | 70% | 0.69      | 0.70   | 0.69     |  

ğŸ“Œ **Ambos modelos superaron el baseline de predicciÃ³n unicamente tomando en cuenta el ranking mas alto entre jugadores (65% de accuracy).**  

## Conclusiones ğŸ  
âœ”ï¸ **SGDClassifier** es mÃ¡s estable y menos propenso a overfitting.  
âœ”ï¸ **KNeighborsClassifier** tuvo un rendimiento alto inicialmente, pero requiriÃ³ reducir variables para evitar sobreajuste.  
âœ”ï¸ **Las variables derivadas (feature engineering) ayudaron a mejorar la precisiÃ³n del modelo.**  

## Recomendaciones ğŸ“Œ  
- Evitar **overfitting** en K-NN usando validaciÃ³n cruzada y selecciÃ³n de variables.  
